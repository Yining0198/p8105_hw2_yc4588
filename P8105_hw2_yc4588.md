p8105_hw2_yc4588
================
Yining Cao
2024-09-30

# Problem 1

## Import and clean the dataset

``` r
library(readr)
library(dplyr)
```

    ## 
    ## Attaching package: 'dplyr'

    ## The following objects are masked from 'package:stats':
    ## 
    ##     filter, lag

    ## The following objects are masked from 'package:base':
    ## 
    ##     intersect, setdiff, setequal, union

``` r
ent_exit = read_csv("NYC_Transit_Subway_Entrance_And_Exit_Data.csv",na = c("NA", "", "."))
```

    ## Rows: 1868 Columns: 32

    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
colnames(ent_exit)
```

    ##  [1] "Division"           "Line"               "Station Name"      
    ##  [4] "Station Latitude"   "Station Longitude"  "Route1"            
    ##  [7] "Route2"             "Route3"             "Route4"            
    ## [10] "Route5"             "Route6"             "Route7"            
    ## [13] "Route8"             "Route9"             "Route10"           
    ## [16] "Route11"            "Entrance Type"      "Entry"             
    ## [19] "Exit Only"          "Vending"            "Staffing"          
    ## [22] "Staff Hours"        "ADA"                "ADA Notes"         
    ## [25] "Free Crossover"     "North South Street" "East West Street"  
    ## [28] "Corner"             "Entrance Latitude"  "Entrance Longitude"
    ## [31] "Station Location"   "Entrance Location"

- The variables in the dataset include: *Division*(BMT, IND, etc),
  *Line*(“4 avenue”, “42nd St Shuttle”, “6 avenue”, etc.), *Station
  Name*(“25th St”, “36th St”, “45th St”, etc) and so on.

``` r
library(tidyr)
ent_exit_df <- ent_exit |>
  janitor::clean_names()|>
  mutate(entry = case_match(
    entry,
    "YES" ~ TRUE,
    "NO" ~ FALSE
  )) |>
  select(line,
         station_name, 
         station_latitude, 
         station_longitude, 
         starts_with("route"),
         entry, 
         vending, 
         entrance_type, 
         ada)
ent_exit_df
```

    ## # A tibble: 1,868 × 19
    ##    line     station_name station_latitude station_longitude route1 route2 route3
    ##    <chr>    <chr>                   <dbl>             <dbl> <chr>  <chr>  <chr> 
    ##  1 4 Avenue 25th St                  40.7             -74.0 R      <NA>   <NA>  
    ##  2 4 Avenue 25th St                  40.7             -74.0 R      <NA>   <NA>  
    ##  3 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ##  4 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ##  5 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ##  6 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ##  7 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ##  8 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ##  9 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ## 10 4 Avenue 53rd St                  40.6             -74.0 R      <NA>   <NA>  
    ## # ℹ 1,858 more rows
    ## # ℹ 12 more variables: route4 <chr>, route5 <chr>, route6 <chr>, route7 <chr>,
    ## #   route8 <dbl>, route9 <dbl>, route10 <dbl>, route11 <dbl>, entry <lgl>,
    ## #   vending <chr>, entrance_type <chr>, ada <lgl>

- The dataset contains information about subway entrances and exits in
  New York City, with variables including *line*, *station_name*,
  *station_latitude*, *station_longitude*, *route1-route11*, *entry*,
  *vending*, *entrance_type*, and *ada*. `line` is a categorical
  variable describing the NYC transit subway lines.  
  `station_name` is a categorical variable describing the names of the
  subway stations.  
  `station_latitude` and `station_longitude` are numerical variables
  representing the latitude and longitude of the subway stations.  
  `route1` to `route11` are categorical variables describing the routes
  associated with each subway station.  
  `entry` is a logical variable indicating whether the entrance allows
  entry.  
  `vending` is a categorical variable indicating whether vending
  machines are available.  
  `entrance_type` is a categorical variable describing the type of
  entrance.  
  `ada` is a categorical variable indicating whether the station is
  ADA-compliant.  
- cleaning steps:
  1.  Using na=c(“NA”, ““,”.”) to clean the missing values.
  2.  Clean column names using the `janitor::clean_names()` function.
  3.  Convert the `entry` column to a logical variable using the
      `case_match()` function.
  4.  Select the columns of interest with `select()` function, including
      `line`, `station_name`, `station_latitude`, `station_longitude`,
      `route1` to `route11`, `entry`, `vending`, `entrance_type`, and
      `ada`.
- This dataset contains 1868 rows and 19 columns after cleaning.
- These data are not tidy enough because the `route1` to `route11`
  columns are not in a long format.

## How many distinct satation are here?

``` r
distinct_stations <- ent_exit_df |> 
  distinct(line, station_name) |> 
  nrow()
```

- There are 465 distinct stations in the dataset.

## How many stations are ADA compliant?

``` r
ada_stations <- ent_exit_df |>
  filter(ada == "TRUE") |>
  distinct(station_name, line) |>
  nrow()
```

- There are 84 ADA-compliant stations in the dataset.

## What proportion of station entrances / exits without vending allow entrance?

``` r
no_vending_entry <- ent_exit_df |>
  filter(vending == "NO") |>
  summarise(prop_entry = mean(entry, na.rm = TRUE))
```

- The proportion of station entrances/exits without vending that allow
  entrance is 0.3770492.

## Reformat the data so that route number and route name are distinct

``` r
ent_exit_df <- ent_exit_df |>
  mutate(across(starts_with("route"), as.character)) |> 
  pivot_longer(cols = starts_with("route"), 
               names_to = "route_number", 
               values_to = "route_name")
```

## How many distinct stations serve the A train?

``` r
A_train_stations <- ent_exit_df |>
  filter(route_name == "A") |>
  distinct(station_name, line) |>
  nrow()
```

- There are 60 distinct stations that serve the A train.

## Of the stations that serve the A train, how many are ADA compliant?

``` r
A_train_ada_stations <- ent_exit_df |>
  filter(route_name == "A") |>
  filter(ada == "TRUE") |>
  distinct(station_name, line) |>
  nrow()
```

- There are 17 ADA-compliant stations that serve the A train.

# Problem 2

## Import and clean the *Mr. Trash Wheel* dataset

``` r
library(readxl)
Mr_trash_wheel =  readxl::read_excel("202409 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N655",na = c("NA", "", ".")) |>
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |> 
  mutate(sports_balls = as.integer(round(sports_balls)))
```

## Import and clean the *Professor Trash Wheel* dataset and the *Gwynnda Trash Wheel* dataset

``` r
Professor_trash_wheel =  readxl::read_excel("202409 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = "A2:M120",na = c("NA", "", ".")) |>
  janitor::clean_names()|>
  filter(!is.na(dumpster))

Gwynnda_trash_wheel =  readxl::read_excel("202409 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", range = "A2:L266",na = c("NA", "", ".")) |>
  janitor::clean_names()|>
  filter(!is.na(dumpster))
```

## Describe these three datasets

``` r
summary(Mr_trash_wheel)
```

    ##     dumpster        month               year          
    ##  Min.   :  1.0   Length:651         Length:651        
    ##  1st Qu.:163.5   Class :character   Class :character  
    ##  Median :326.0   Mode  :character   Mode  :character  
    ##  Mean   :326.0                                        
    ##  3rd Qu.:488.5                                        
    ##  Max.   :651.0                                        
    ##                                                       
    ##       date                         weight_tons    volume_cubic_yards
    ##  Min.   :2014-05-16 00:00:00.00   Min.   :0.780   Min.   : 7.00     
    ##  1st Qu.:2016-12-03 12:00:00.00   1st Qu.:2.720   1st Qu.:15.00     
    ##  Median :2019-04-18 00:00:00.00   Median :3.200   Median :15.00     
    ##  Mean   :2019-04-16 09:39:32.34   Mean   :3.212   Mean   :15.24     
    ##  3rd Qu.:2021-09-02 00:00:00.00   3rd Qu.:3.725   3rd Qu.:15.00     
    ##  Max.   :2024-06-11 00:00:00.00   Max.   :5.620   Max.   :20.00     
    ##                                                                     
    ##  plastic_bottles  polystyrene   cigarette_butts  glass_bottles   
    ##  Min.   :  80    Min.   :  20   Min.   :   500   Min.   :  0.00  
    ##  1st Qu.:1008    1st Qu.: 400   1st Qu.:  3600   1st Qu.: 10.00  
    ##  Median :1900    Median : 990   Median :  5600   Median : 18.00  
    ##  Mean   :1966    Mean   :1425   Mean   : 18136   Mean   : 21.37  
    ##  3rd Qu.:2735    3rd Qu.:2240   3rd Qu.: 21500   3rd Qu.: 29.00  
    ##  Max.   :5960    Max.   :6540   Max.   :310000   Max.   :110.00  
    ##                                                                  
    ##   plastic_bags       wrappers     sports_balls   homes_powered  
    ##  Min.   :  24.0   Min.   : 180   Min.   : 0.00   Min.   : 0.00  
    ##  1st Qu.: 265.0   1st Qu.: 780   1st Qu.: 6.00   1st Qu.:41.00  
    ##  Median : 510.0   Median :1200   Median :12.00   Median :51.67  
    ##  Mean   : 849.1   Mean   :1452   Mean   :13.98   Mean   :47.73  
    ##  3rd Qu.:1120.0   3rd Qu.:2000   3rd Qu.:20.00   3rd Qu.:60.33  
    ##  Max.   :3750.0   Max.   :5085   Max.   :56.00   Max.   :93.67  
    ##                                                  NA's   :22

``` r
summary(Professor_trash_wheel)
```

    ##     dumpster         month                year     
    ##  Min.   :  1.00   Length:118         Min.   :2017  
    ##  1st Qu.: 30.25   Class :character   1st Qu.:2018  
    ##  Median : 59.50   Mode  :character   Median :2020  
    ##  Mean   : 59.50                      Mean   :2020  
    ##  3rd Qu.: 88.75                      3rd Qu.:2022  
    ##  Max.   :118.00                      Max.   :2024  
    ##                                                    
    ##       date                         weight_tons    volume_cubic_yards
    ##  Min.   :2017-01-02 00:00:00.00   Min.   :0.610   Min.   : 6.00     
    ##  1st Qu.:2018-06-24 00:00:00.00   1st Qu.:1.637   1st Qu.:15.00     
    ##  Median :2020-03-05 12:00:00.00   Median :2.000   Median :15.00     
    ##  Mean   :2020-05-06 07:19:19.31   Mean   :2.091   Mean   :14.54     
    ##  3rd Qu.:2022-04-03 18:00:00.00   3rd Qu.:2.535   3rd Qu.:15.00     
    ##  Max.   :2024-05-30 00:00:00.00   Max.   :3.750   Max.   :18.00     
    ##                                                                     
    ##  plastic_bottles  polystyrene    cigarette_butts glass_bottles  
    ##  Min.   : 657    Min.   :  180   Min.   : 3800   Min.   : 0.00  
    ##  1st Qu.:3600    1st Qu.:  640   1st Qu.: 6200   1st Qu.: 9.00  
    ##  Median :4800    Median : 3100   Median : 8380   Median :18.00  
    ##  Mean   :5070    Mean   : 3816   Mean   :10919   Mean   :18.38  
    ##  3rd Qu.:6800    3rd Qu.: 6400   3rd Qu.:14000   3rd Qu.:26.00  
    ##  Max.   :9830    Max.   :11528   Max.   :33320   Max.   :49.00  
    ##  NA's   :1       NA's   :1       NA's   :1       NA's   :1      
    ##   plastic_bags      wrappers     homes_powered  
    ##  Min.   :  140   Min.   : 2300   Min.   :10.17  
    ##  1st Qu.:  440   1st Qu.: 4300   1st Qu.:26.92  
    ##  Median :  980   Median : 5500   Median :33.08  
    ##  Mean   : 2219   Mean   : 7390   Mean   :34.40  
    ##  3rd Qu.: 1800   3rd Qu.: 8800   3rd Qu.:41.92  
    ##  Max.   :13450   Max.   :20100   Max.   :62.00  
    ##  NA's   :1       NA's   :1       NA's   :4

``` r
summary(Gwynnda_trash_wheel)
```

    ##     dumpster        month                year     
    ##  Min.   :  1.0   Length:263         Min.   :2021  
    ##  1st Qu.: 65.5   Class :character   1st Qu.:2022  
    ##  Median :131.0   Mode  :character   Median :2022  
    ##  Mean   :131.1                      Mean   :2022  
    ##  3rd Qu.:196.5                      3rd Qu.:2023  
    ##  Max.   :262.0                      Max.   :2024  
    ##                                                   
    ##       date                         weight_tons    volume_cubic_yards
    ##  Min.   :2021-07-03 00:00:00.00   Min.   :0.770   Min.   : 5.00     
    ##  1st Qu.:2022-04-22 12:00:00.00   1st Qu.:2.700   1st Qu.:15.00     
    ##  Median :2022-12-30 00:00:00.00   Median :3.080   Median :15.00     
    ##  Mean   :2023-01-07 10:02:16.88   Mean   :3.033   Mean   :14.92     
    ##  3rd Qu.:2023-11-29 12:00:00.00   3rd Qu.:3.445   3rd Qu.:15.00     
    ##  Max.   :2024-06-07 00:00:00.00   Max.   :4.240   Max.   :15.00     
    ##                                                                     
    ##  plastic_bottles  polystyrene    cigarette_butts  plastic_bags   
    ##  Min.   :   0    Min.   :  0.0   Min.   :   0    Min.   :   0.0  
    ##  1st Qu.: 720    1st Qu.: 82.0   1st Qu.:1200    1st Qu.: 120.0  
    ##  Median :1200    Median :190.0   Median :2200    Median : 240.0  
    ##  Mean   :1507    Mean   :197.9   Mean   :2372    Mean   : 545.1  
    ##  3rd Qu.:2100    3rd Qu.:275.0   3rd Qu.:3300    3rd Qu.: 640.0  
    ##  Max.   :5400    Max.   :640.0   Max.   :6400    Max.   :3600.0  
    ##                                                                  
    ##     wrappers    homes_powered  
    ##  Min.   :   0   Min.   :12.83  
    ##  1st Qu.: 980   1st Qu.:43.92  
    ##  Median :1600   Median :50.08  
    ##  Mean   :1666   Mean   :49.45  
    ##  3rd Qu.:2100   3rd Qu.:56.50  
    ##  Max.   :4900   Max.   :70.67  
    ##  NA's   :117    NA's   :43

## Combine the three datasets

``` r
# switch the year column of Mr. Trash Whell dataset to integer
Mr_trash_wheel <- Mr_trash_wheel |> 
  mutate(year = as.integer(year))

trash_wheel_df <- bind_rows(
  Mr_trash_wheel |>
    mutate(trash_wheel = "Mr. Trash Wheel"),
  Professor_trash_wheel |>
    mutate(trash_wheel = "Professor Trash Wheel"),
  Gwynnda_trash_wheel |>
    mutate(trash_wheel = "Gwynnda Trash Wheel")
)
trash_wheel_df
```

    ## # A tibble: 1,032 × 15
    ##    dumpster month  year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr> <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 May    2014 2014-05-16 00:00:00        4.31                 18
    ##  2        2 May    2014 2014-05-16 00:00:00        2.74                 13
    ##  3        3 May    2014 2014-05-16 00:00:00        3.45                 15
    ##  4        4 May    2014 2014-05-17 00:00:00        3.1                  15
    ##  5        5 May    2014 2014-05-17 00:00:00        4.06                 18
    ##  6        6 May    2014 2014-05-20 00:00:00        2.71                 13
    ##  7        7 May    2014 2014-05-21 00:00:00        1.91                  8
    ##  8        8 May    2014 2014-05-28 00:00:00        3.7                  16
    ##  9        9 June   2014 2014-06-05 00:00:00        2.52                 14
    ## 10       10 June   2014 2014-06-11 00:00:00        3.76                 18
    ## # ℹ 1,022 more rows
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <int>, homes_powered <dbl>, trash_wheel <chr>

- The combined dataset integrates information from three distinct trash
  wheels: Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda Trash
  Wheel.

- The resulting dataset contains 1032 observations and 15 variables.

- The variables in the dataset include: `dumpster`: the number of the
  dumpster (Mr:651; Professor:119; Gwynnda:262).  
  `month`: the month of the year.(January - December)  
  `year`: the year of the data collection.(Mr:2014-2024;
  Professor:2017-2024; Gwynnda:2021-2024)  
  `date`: the date of the data collection.( Mr:2014-05-16~2024-06-11;
  Professor: 2017-01-02~2024-05-30; 2021-07-03~2024-06-07)  
  `weight_tons`: the weight of trash collected in tons.(Mr:0.780 -
  5.620; Professor:0.610-3.750; Gwynnda:0.770-4.240)  
  `volum_cubic_yards`: the volume of trash collected in cubic
  yards.(Mr:7.0~20.0; Professor:6.0-18.0; Gwynnda:5.0-15.0)  
  `plastic_botles`: the number of plastic bottles collected.(Mr:80-5940;
  Professor:657-9830; Gwynnda:0-5400)  
  `polystyrene`: the number of polystyrene collected.(Mr:20-6540;
  Professor:180-11528; Gwynnda:0~5)  
  `cigarette_butts`: the number of cigarette butts
  collected.(Mr:500-31000; Professor:3800-33320; Gwynnda:0.0-640.0)  
  `glass_bottles`: the number of glass bottles collected.(Mr:0-110;
  Professor:0-49; Gwynnda:0-6400)  
  `plastic_bags`: the number of plastic bags collected.(Mr:24-3750;
  Professor:140-13450; Gwynnda:0.0-3600.0)  
  `wrappers`: the number of wrappers collected.(Mr:180-5085;
  Professor:2300-20100; Gwynnda:0-4900)  
  `sports_balls`: the number of sports balls collected.(Mr:0-56)  
  `home_powered`: the number of home powered collected.(Mr:0-22;
  Professor:10.17-22.00; Gwynnda:12.83-70.67)  
  `trash_wheel`: the name of the trash wheel (Mr. Trash Wheel, Professor
  Trash Wheel, Gwynnda Trash Wheel).

- The total weight of trash collected by Professor Trash Wheel is 246.74
  tons.

- In June 2022, Gwynnda collected a total of 40.53 tons of trash.

# Problem 3

## Import and clean three datesets of individual bakers, their bakes, and their performance

``` r
bakers = read_csv("gbb_datasets/bakers.csv",na = c("NA", "", ".")) |>
  janitor::clean_names()|>
  mutate(
    baker_name = sub(" .*", "", baker_name)
  ) |>
  rename(baker = baker_name)|>
  mutate(
    baker = replace(baker, baker == "Jo", "Joanne")
  )
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bakes = read_csv("gbb_datasets/bakes.csv", col_names = TRUE, na = c("NA", "", ".")) |>
  janitor::clean_names() |>
  mutate(
    baker = replace(baker, baker == '"Jo"', "Joanne")
  )
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
results = read_csv("gbb_datasets/results.csv",skip = 2, na = c("N/A", "NA", "UNKNOWN","", "Unknown")) |>
  janitor::clean_names()
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

## Merge the three datasets

``` r
 merged_data = 
  left_join(results, bakes, 
            by = join_by(series, episode, baker)) |>
  left_join(bakers,
            by = join_by(series, baker)) |>
  select(baker, everything())
```

## Checking for completeness and correctness across datasets

``` r
anti_join(results, merged_data,
          by = join_by(series, episode, baker, technical, result))
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: series <dbl>, episode <dbl>, baker <chr>, technical <dbl>,
    ## #   result <chr>

``` r
anti_join(bakes, merged_data,
          by = join_by(series, episode, baker, signature_bake,show_stopper))
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: series <dbl>, episode <dbl>, baker <chr>,
    ## #   signature_bake <chr>, show_stopper <chr>

``` r
anti_join(bakers, merged_data, 
          by = join_by(baker,series, baker_age,baker_occupation, hometown))
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: baker <chr>, series <dbl>, baker_age <dbl>,
    ## #   baker_occupation <chr>, hometown <chr>

- These datasets are complete and correct because the `anti_join()`
  function returns an empty data frame for all three datasets.

## Export the merged dataset

``` r
write.csv(merged_data, "gbb_datasets/merged_data.csv", row.names = FALSE)
```

- Cleaning steps:
  1.  Using na = c(“NA”, ““,”.”)/c(“N/A”, “NA”, “UNKNOWN”,““,”Unknown”)
      to clean the missing values.
  2.  Clean column names using the `janitor::clean_names()` function.
  3.  Remove the last name from the `baker_name` column using the
      `sub()` function.
  4.  Rename the `baker_name` column to `baker`.
  5.  Replace the name “Jo” with “Joanne” in the `baker`columns of all
      three datasets.
  6.  Skip the first two rows in the `results` dataset using the `skip`
      argument.
  7.  After merging the datasets, check for completeness and correctness
      using the `anti_join()` function.
- The merged dataset contains 1136 observations and 10 variables.
- The variables in the dataset include: *baker*, *series*, *episode*,
  *technical*, *result*, *signature_bake*, *show_stopper*, *baker_age*,
  *baker_occupation*, and *hometown*.

## Creating a reader-friendly table showing the star baker or winner of each episode in Seasons 5 through 10

``` r
star_baker_table = merged_data |>
  filter(result %in% c("STAR BAKER", "WINNER")) |>
  filter(series %in% c(5:10)) |> 
  arrange(series, episode) |>
  select(episode, baker, series) |>
  pivot_wider(
    names_from = "series",
    values_from = "baker"  ) |>
  rename("series 5" = "5",
         "series 6" = "6",
         "series 7" = "7",
         "series 8" = "8",
         "series 9" = "9",
         "series 10" = "10") |>
  knitr::kable()

star_baker_table
```

| episode | series 5 | series 6 | series 7  | series 8 | series 9 | series 10 |
|--------:|:---------|:---------|:----------|:---------|:---------|:----------|
|       1 | Nancy    | Marie    | Jane      | Steven   | Manon    | Michelle  |
|       2 | Richard  | Ian      | Candice   | Steven   | Rahul    | Alice     |
|       3 | Luis     | Ian      | Tom       | Julia    | Rahul    | Michael   |
|       4 | Richard  | Ian      | Benjamina | Kate     | Dan      | Steph     |
|       5 | Kate     | Nadiya   | Candice   | Sophie   | Kim-Joy  | Steph     |
|       6 | Chetna   | Mat      | Tom       | Liam     | Briony   | Steph     |
|       7 | Richard  | Tamal    | Andrew    | Steven   | Kim-Joy  | Henry     |
|       8 | Richard  | Nadiya   | Candice   | Stacey   | Ruby     | Steph     |
|       9 | Richard  | Nadiya   | Andrew    | Sophie   | Ruby     | Alice     |
|      10 | Nancy    | Nadiya   | Candice   | Sophie   | Rahul    | David     |

- Richard won the star baker or winner title 5 times in series 5.
- Nadiya won the star baker or winner title 4 times in series 6.
- Candice won the star baker or winner title 4 times in series 7.
- Steven and Sophie won the star baker or winner title 3 times in series
  8, respectively.
- Rahul won the star baker or winner title 3 times in series 9.
- Steph won the star baker or winner title 4 times in series 10.
- The winners, such as Richard, Candice, and Steven, are overall
  predictable, while the winners, such as Nadiya, Sophie, and Steph, are
  relatively unexpected because they won fewer star baker titles or
  winner titles in the early episodes of their respective series, which
  may surprised the audience.

## Import and clean viewers dataset

``` r
viewers = read_csv("gbb_datasets/viewers.csv", na = c("NA", "", ".")) |>
  janitor::clean_names()
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

## What was the average viewership in Season 1? In Season 5?

``` r
head(viewers,10)
```

    ## # A tibble: 10 × 11
    ##    episode series_1 series_2 series_3 series_4 series_5 series_6 series_7
    ##      <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>
    ##  1       1     2.24     3.1      3.85     6.6      8.51     11.6     13.6
    ##  2       2     3        3.53     4.6      6.65     8.79     11.6     13.4
    ##  3       3     3        3.82     4.53     7.17     9.28     12.0     13.0
    ##  4       4     2.6      3.6      4.71     6.82    10.2      12.4     13.3
    ##  5       5     3.03     3.83     4.61     6.95     9.95     12.4     13.1
    ##  6       6     2.75     4.25     4.82     7.32    10.1      12       13.1
    ##  7       7    NA        4.42     5.1      7.76    10.3      12.4     13.4
    ##  8       8    NA        5.06     5.35     7.41     9.02     11.1     13.3
    ##  9       9    NA       NA        5.7      7.41    10.7      12.6     13.4
    ## 10      10    NA       NA        6.74     9.45    13.5      15.0     15.9
    ## # ℹ 3 more variables: series_8 <dbl>, series_9 <dbl>, series_10 <dbl>

- The average viewership in Season 1 was 2.77 million.
- The average viewership in Season 5 was 10.0393 million.
